{
  "checkpoint": "results/hateBERT/GroNLP_hateBERT",
  "overall_metrics": {
    "accuracy": 0.9679162609542357,
    "precision": 0.9625922555858861,
    "recall": 0.9705402650356779,
    "f1": 0.9665499213237907
  },
  "subgroup_metrics": {
    "target_race_asian": {
      "accuracy": 0.9896743447180302,
      "precision": 0.993006993006993,
      "recall": 0.9888579387186629,
      "f1": 0.9909281228192603,
      "fpr": 0.009242144177449169,
      "fnr": 0.011142061281337047
    },
    "target_race_black": {
      "accuracy": 0.9780663780663781,
      "precision": 0.9812821712681329,
      "recall": 0.9831223628691983,
      "f1": 0.9822014051522249,
      "fpr": 0.03003003003003003,
      "fnr": 0.016877637130801686
    },
    "target_race_latinx": {
      "accuracy": 0.9843416370106761,
      "precision": 0.9907407407407407,
      "recall": 0.9839080459770115,
      "f1": 0.9873125720876585,
      "fpr": 0.014953271028037384,
      "fnr": 0.016091954022988506
    },
    "target_race_middle_eastern": {
      "accuracy": 0.9771986970684039,
      "precision": 0.982532751091703,
      "recall": 0.9793253536452666,
      "f1": 0.9809264305177112,
      "fpr": 0.025974025974025976,
      "fnr": 0.020674646354733407
    },
    "target_race_native_american": {
      "accuracy": 0.9862700228832952,
      "precision": 0.9891304347826086,
      "recall": 0.9479166666666666,
      "f1": 0.9680851063829787,
      "fpr": 0.002932551319648094,
      "fnr": 0.052083333333333336
    },
    "target_race_pacific_islander": {
      "accuracy": 0.981081081081081,
      "precision": 0.9826086956521739,
      "recall": 0.9576271186440678,
      "f1": 0.9699570815450643,
      "fpr": 0.007936507936507936,
      "fnr": 0.0423728813559322
    },
    "target_race_white": {
      "accuracy": 0.9663191659983962,
      "precision": 0.9609544468546638,
      "recall": 0.9486081370449678,
      "f1": 0.9547413793103449,
      "fpr": 0.023076923076923078,
      "fnr": 0.05139186295503212
    },
    "target_race_other": {
      "accuracy": 0.9653259361997226,
      "precision": 0.9555555555555556,
      "recall": 0.9745042492917847,
      "f1": 0.9649368863955119,
      "fpr": 0.043478260869565216,
      "fnr": 0.025495750708215296
    },
    "target_religion_atheist": {
      "accuracy": 0.9705882352941176,
      "precision": 0.9473684210526315,
      "recall": 0.9473684210526315,
      "f1": 0.9473684210526315,
      "fpr": 0.02040816326530612,
      "fnr": 0.05263157894736842
    },
    "target_religion_buddhist": {
      "accuracy": 0.9583333333333334,
      "precision": 0.9444444444444444,
      "recall": 0.9444444444444444,
      "f1": 0.9444444444444444,
      "fpr": 0.03333333333333333,
      "fnr": 0.05555555555555555
    },
    "target_religion_christian": {
      "accuracy": 0.9624463519313304,
      "precision": 0.8817204301075269,
      "recall": 0.9265536723163842,
      "f1": 0.9035812672176309,
      "fpr": 0.02913907284768212,
      "fnr": 0.07344632768361582
    },
    "target_religion_hindu": {
      "accuracy": 0.9781420765027322,
      "precision": 0.9692307692307692,
      "recall": 0.9692307692307692,
      "f1": 0.9692307692307692,
      "fpr": 0.01694915254237288,
      "fnr": 0.03076923076923077
    },
    "target_religion_jewish": {
      "accuracy": 0.977796754910333,
      "precision": 0.9814207650273225,
      "recall": 0.9900771775082691,
      "f1": 0.9857299670691547,
      "fpr": 0.06439393939393939,
      "fnr": 0.009922822491730982
    },
    "target_religion_mormon": {
      "accuracy": 0.9747899159663865,
      "precision": 0.9722222222222222,
      "recall": 0.9459459459459459,
      "f1": 0.958904109589041,
      "fpr": 0.012195121951219513,
      "fnr": 0.05405405405405406
    },
    "target_religion_muslim": {
      "accuracy": 0.9837358304583539,
      "precision": 0.9860696517412936,
      "recall": 0.9811881188118812,
      "f1": 0.9836228287841191,
      "fpr": 0.013738959764474975,
      "fnr": 0.01881188118811881
    },
    "target_religion_other": {
      "accuracy": 0.978328173374613,
      "precision": 1.0,
      "recall": 0.9222222222222223,
      "f1": 0.9595375722543352,
      "fpr": 0.0,
      "fnr": 0.07777777777777778
    },
    "target_origin_immigrant": {
      "accuracy": 0.9737171464330413,
      "precision": 0.9867608120035305,
      "recall": 0.9764192139737992,
      "f1": 0.9815627743634767,
      "fpr": 0.033112582781456956,
      "fnr": 0.023580786026200874
    },
    "target_origin_migrant_worker": {
      "accuracy": 0.9679802955665024,
      "precision": 0.9794520547945206,
      "recall": 0.9761092150170648,
      "f1": 0.9777777777777777,
      "fpr": 0.05309734513274336,
      "fnr": 0.023890784982935155
    },
    "target_origin_specific_country": {
      "accuracy": 0.9661813057773603,
      "precision": 0.9573333333333334,
      "recall": 0.9782016348773842,
      "f1": 0.967654986522911,
      "fpr": 0.04669260700389105,
      "fnr": 0.021798365122615803
    },
    "target_origin_undocumented": {
      "accuracy": 0.977,
      "precision": 0.9876712328767123,
      "recall": 0.9809523809523809,
      "f1": 0.9843003412969283,
      "fpr": 0.033962264150943396,
      "fnr": 0.01904761904761905
    },
    "target_origin_other": {
      "accuracy": 0.9685863874345549,
      "precision": 0.971830985915493,
      "recall": 0.971830985915493,
      "f1": 0.971830985915493,
      "fpr": 0.03550295857988166,
      "fnr": 0.028169014084507043
    },
    "target_gender_men": {
      "accuracy": 0.9465361445783133,
      "precision": 0.9060402684563759,
      "recall": 0.9331797235023042,
      "f1": 0.9194097616345063,
      "fpr": 0.04697986577181208,
      "fnr": 0.06682027649769585
    },
    "target_gender_non_binary": {
      "accuracy": 0.9638888888888889,
      "precision": 0.9565217391304348,
      "recall": 0.868421052631579,
      "f1": 0.9103448275862069,
      "fpr": 0.01056338028169014,
      "fnr": 0.13157894736842105
    },
    "target_gender_transgender_men": {
      "accuracy": 0.9677996422182469,
      "precision": 0.9454545454545454,
      "recall": 0.896551724137931,
      "f1": 0.9203539823008849,
      "fpr": 0.013544018058690745,
      "fnr": 0.10344827586206896
    },
    "target_gender_transgender_unspecified": {
      "accuracy": 0.9893867924528302,
      "precision": 0.9540229885057471,
      "recall": 0.9431818181818182,
      "f1": 0.9485714285714286,
      "fpr": 0.005263157894736842,
      "fnr": 0.056818181818181816
    },
    "target_gender_transgender_women": {
      "accuracy": 0.9655172413793104,
      "precision": 0.9489795918367347,
      "recall": 0.8942307692307693,
      "f1": 0.9207920792079208,
      "fpr": 0.013888888888888888,
      "fnr": 0.10576923076923077
    },
    "target_gender_women": {
      "accuracy": 0.9522625559423172,
      "precision": 0.9485743380855397,
      "recall": 0.9534288638689867,
      "f1": 0.9509954058192955,
      "fpr": 0.0488394584139265,
      "fnr": 0.0465711361310133
    },
    "target_gender_other": {
      "accuracy": 0.926605504587156,
      "precision": 0.9411764705882353,
      "recall": 0.9056603773584906,
      "f1": 0.9230769230769231,
      "fpr": 0.05357142857142857,
      "fnr": 0.09433962264150944
    },
    "target_sexuality_bisexual": {
      "accuracy": 0.9710526315789474,
      "precision": 0.9481481481481482,
      "recall": 0.9309090909090909,
      "f1": 0.9394495412844037,
      "fpr": 0.016184971098265895,
      "fnr": 0.06909090909090909
    },
    "target_sexuality_gay": {
      "accuracy": 0.969255025620812,
      "precision": 0.9648197009674582,
      "recall": 0.9665198237885463,
      "f1": 0.965669014084507,
      "fpr": 0.028530670470756064,
      "fnr": 0.033480176211453744
    },
    "target_sexuality_lesbian": {
      "accuracy": 0.9700854700854701,
      "precision": 0.9594594594594594,
      "recall": 0.9250814332247557,
      "f1": 0.9419568822553898,
      "fpr": 0.013904982618771726,
      "fnr": 0.0749185667752443
    },
    "target_sexuality_straight": {
      "accuracy": 0.9345661450924608,
      "precision": 0.8938053097345132,
      "recall": 0.9017857142857143,
      "f1": 0.8977777777777778,
      "fpr": 0.05010438413361169,
      "fnr": 0.09821428571428571
    },
    "target_sexuality_other": {
      "accuracy": 0.9700374531835206,
      "precision": 0.918918918918919,
      "recall": 0.8717948717948718,
      "f1": 0.8947368421052632,
      "fpr": 0.013157894736842105,
      "fnr": 0.1282051282051282
    },
    "target_age_children": {
      "accuracy": 0.9285714285714286,
      "precision": 0.8421052631578947,
      "recall": 0.9696969696969697,
      "f1": 0.9014084507042254,
      "fpr": 0.09230769230769231,
      "fnr": 0.030303030303030304
    },
    "target_age_teenagers": {
      "accuracy": 0.9532710280373832,
      "precision": 0.8809523809523809,
      "recall": 1.0,
      "f1": 0.9367088607594937,
      "fpr": 0.07142857142857142,
      "fnr": 0.0
    },
    "target_age_young_adults": {
      "accuracy": 0.9387755102040817,
      "precision": 0.9583333333333334,
      "recall": 0.8679245283018868,
      "f1": 0.9108910891089109,
      "fpr": 0.02127659574468085,
      "fnr": 0.1320754716981132
    },
    "target_age_middle_aged": {
      "accuracy": 0.9090909090909091,
      "precision": 0.9375,
      "recall": 0.8571428571428571,
      "f1": 0.8955223880597015,
      "fpr": 0.047619047619047616,
      "fnr": 0.14285714285714285
    },
    "target_age_seniors": {
      "accuracy": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "f1": 1.0,
      "fpr": 0.0,
      "fnr": 0.0
    },
    "target_age_other": {
      "accuracy": 0.8666666666666667,
      "precision": 1.0,
      "recall": 0.7777777777777778,
      "f1": 0.875,
      "fpr": 0.0,
      "fnr": 0.2222222222222222
    },
    "target_disability_physical": {
      "accuracy": 0.9934640522875817,
      "precision": 0.9925925925925926,
      "recall": 1.0,
      "f1": 0.9962825278810409,
      "fpr": 0.05263157894736842,
      "fnr": 0.0
    },
    "target_disability_cognitive": {
      "accuracy": 0.9742647058823529,
      "precision": 0.9957081545064378,
      "recall": 0.9747899159663865,
      "f1": 0.9851380042462845,
      "fpr": 0.029411764705882353,
      "fnr": 0.025210084033613446
    },
    "target_disability_neurological": {
      "accuracy": 0.9722222222222222,
      "precision": 1.0,
      "recall": 0.9583333333333334,
      "f1": 0.9787234042553191,
      "fpr": 0.0,
      "fnr": 0.041666666666666664
    },
    "target_disability_visually_impaired": {
      "accuracy": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "f1": 1.0,
      "fpr": 0.0,
      "fnr": 0.0
    },
    "target_disability_hearing_impaired": {
      "accuracy": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "f1": 1.0,
      "fpr": 0.0,
      "fnr": 0.0
    },
    "target_disability_unspecific": {
      "accuracy": 0.9782608695652174,
      "precision": 0.9904761904761905,
      "recall": 0.9811320754716981,
      "f1": 0.985781990521327,
      "fpr": 0.03125,
      "fnr": 0.018867924528301886
    },
    "target_disability_other": {
      "accuracy": 0.9310344827586207,
      "precision": 1.0,
      "recall": 0.9090909090909091,
      "f1": 0.9523809523809523,
      "fpr": 0.0,
      "fnr": 0.09090909090909091
    }
  },
  "fairness_metrics": {
    "f1_disparity": 0.03328853792259234,
    "fpr_disparity": 0.021398466472840258,
    "fnr_disparity": 0.046311342372642526
  }
}