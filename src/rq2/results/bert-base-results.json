{
  "checkpoint": "results/bert-base-uncased/bert-base-uncased",
  "overall_metrics": {
    "accuracy": 0.9646056475170399,
    "precision": 0.9585984045238817,
    "recall": 0.9676860346585118,
    "f1": 0.9631207832394867
  },
  "subgroup_metrics": {
    "target_race_asian": {
      "accuracy": 0.9841143764892772,
      "precision": 0.9860724233983287,
      "recall": 0.9860724233983287,
      "f1": 0.9860724233983287,
      "fpr": 0.018484288354898338,
      "fnr": 0.013927576601671309
    },
    "target_race_black": {
      "accuracy": 0.9725829725829725,
      "precision": 0.9735130111524164,
      "recall": 0.9821847163619315,
      "f1": 0.9778296382730455,
      "fpr": 0.04279279279279279,
      "fnr": 0.017815283638068447
    },
    "target_race_latinx": {
      "accuracy": 0.9758007117437723,
      "precision": 0.9826789838337182,
      "recall": 0.9781609195402299,
      "f1": 0.9804147465437788,
      "fpr": 0.028037383177570093,
      "fnr": 0.021839080459770115
    },
    "target_race_middle_eastern": {
      "accuracy": 0.9700325732899023,
      "precision": 0.9791437980241493,
      "recall": 0.970620239390642,
      "f1": 0.9748633879781421,
      "fpr": 0.030844155844155844,
      "fnr": 0.029379760609358
    },
    "target_race_native_american": {
      "accuracy": 0.977116704805492,
      "precision": 0.9574468085106383,
      "recall": 0.9375,
      "f1": 0.9473684210526315,
      "fpr": 0.011730205278592375,
      "fnr": 0.0625
    },
    "target_race_pacific_islander": {
      "accuracy": 0.972972972972973,
      "precision": 0.9655172413793104,
      "recall": 0.9491525423728814,
      "f1": 0.9572649572649573,
      "fpr": 0.015873015873015872,
      "fnr": 0.05084745762711865
    },
    "target_race_white": {
      "accuracy": 0.9639133921411387,
      "precision": 0.9547413793103449,
      "recall": 0.9486081370449678,
      "f1": 0.9516648764769066,
      "fpr": 0.026923076923076925,
      "fnr": 0.05139186295503212
    },
    "target_race_other": {
      "accuracy": 0.957004160887656,
      "precision": 0.952247191011236,
      "recall": 0.9603399433427762,
      "f1": 0.9562764456981664,
      "fpr": 0.04619565217391304,
      "fnr": 0.039660056657223795
    },
    "target_religion_atheist": {
      "accuracy": 0.9485294117647058,
      "precision": 0.8974358974358975,
      "recall": 0.9210526315789473,
      "f1": 0.9090909090909091,
      "fpr": 0.04081632653061224,
      "fnr": 0.07894736842105263
    },
    "target_religion_buddhist": {
      "accuracy": 0.9166666666666666,
      "precision": 0.8888888888888888,
      "recall": 0.8888888888888888,
      "f1": 0.8888888888888888,
      "fpr": 0.06666666666666667,
      "fnr": 0.1111111111111111
    },
    "target_religion_christian": {
      "accuracy": 0.9624463519313304,
      "precision": 0.8901098901098901,
      "recall": 0.9152542372881356,
      "f1": 0.9025069637883009,
      "fpr": 0.026490066225165563,
      "fnr": 0.0847457627118644
    },
    "target_religion_hindu": {
      "accuracy": 0.9508196721311475,
      "precision": 0.9375,
      "recall": 0.9230769230769231,
      "f1": 0.9302325581395349,
      "fpr": 0.03389830508474576,
      "fnr": 0.07692307692307693
    },
    "target_religion_jewish": {
      "accuracy": 0.9718189581554227,
      "precision": 0.975,
      "recall": 0.9889746416758545,
      "f1": 0.9819376026272578,
      "fpr": 0.08712121212121213,
      "fnr": 0.011025358324145534
    },
    "target_religion_mormon": {
      "accuracy": 0.9411764705882353,
      "precision": 0.875,
      "recall": 0.9459459459459459,
      "f1": 0.9090909090909091,
      "fpr": 0.06097560975609756,
      "fnr": 0.05405405405405406
    },
    "target_religion_muslim": {
      "accuracy": 0.9802858551010349,
      "precision": 0.9801980198019802,
      "recall": 0.9801980198019802,
      "f1": 0.9801980198019802,
      "fpr": 0.019627085377821395,
      "fnr": 0.019801980198019802
    },
    "target_religion_other": {
      "accuracy": 0.9752321981424149,
      "precision": 0.9767441860465116,
      "recall": 0.9333333333333333,
      "f1": 0.9545454545454546,
      "fpr": 0.008583690987124463,
      "fnr": 0.06666666666666667
    },
    "target_origin_immigrant": {
      "accuracy": 0.9680851063829787,
      "precision": 0.9815140845070423,
      "recall": 0.9737991266375546,
      "f1": 0.9776413853572994,
      "fpr": 0.046357615894039736,
      "fnr": 0.026200873362445413
    },
    "target_origin_migrant_worker": {
      "accuracy": 0.9729064039408867,
      "precision": 0.9828767123287672,
      "recall": 0.9795221843003413,
      "f1": 0.9811965811965812,
      "fpr": 0.04424778761061947,
      "fnr": 0.020477815699658702
    },
    "target_origin_specific_country": {
      "accuracy": 0.9643024894316581,
      "precision": 0.9646418857660924,
      "recall": 0.9663941871026339,
      "f1": 0.9655172413793104,
      "fpr": 0.037937743190661476,
      "fnr": 0.03360581289736603
    },
    "target_origin_undocumented": {
      "accuracy": 0.969,
      "precision": 0.9821917808219178,
      "recall": 0.9755102040816327,
      "f1": 0.978839590443686,
      "fpr": 0.04905660377358491,
      "fnr": 0.024489795918367346
    },
    "target_origin_other": {
      "accuracy": 0.9581151832460733,
      "precision": 0.9624413145539906,
      "recall": 0.9624413145539906,
      "f1": 0.9624413145539906,
      "fpr": 0.047337278106508875,
      "fnr": 0.03755868544600939
    },
    "target_gender_men": {
      "accuracy": 0.9344879518072289,
      "precision": 0.8715203426124197,
      "recall": 0.9377880184331797,
      "f1": 0.9034406215316315,
      "fpr": 0.06711409395973154,
      "fnr": 0.06221198156682028
    },
    "target_gender_non_binary": {
      "accuracy": 0.9722222222222222,
      "precision": 0.9459459459459459,
      "recall": 0.9210526315789473,
      "f1": 0.9333333333333333,
      "fpr": 0.014084507042253521,
      "fnr": 0.07894736842105263
    },
    "target_gender_transgender_men": {
      "accuracy": 0.962432915921288,
      "precision": 0.9357798165137615,
      "recall": 0.8793103448275862,
      "f1": 0.9066666666666666,
      "fpr": 0.01580135440180587,
      "fnr": 0.1206896551724138
    },
    "target_gender_transgender_unspecified": {
      "accuracy": 0.9870283018867925,
      "precision": 0.9425287356321839,
      "recall": 0.9318181818181818,
      "f1": 0.9371428571428572,
      "fpr": 0.006578947368421052,
      "fnr": 0.06818181818181818
    },
    "target_gender_transgender_women": {
      "accuracy": 0.9676724137931034,
      "precision": 0.9405940594059405,
      "recall": 0.9134615384615384,
      "f1": 0.926829268292683,
      "fpr": 0.016666666666666666,
      "fnr": 0.08653846153846154
    },
    "target_gender_women": {
      "accuracy": 0.9470412729985082,
      "precision": 0.9398686205154119,
      "recall": 0.9518935516888434,
      "f1": 0.9458428680396643,
      "fpr": 0.05754352030947776,
      "fnr": 0.048106448311156604
    },
    "target_gender_other": {
      "accuracy": 0.908256880733945,
      "precision": 0.9056603773584906,
      "recall": 0.9056603773584906,
      "f1": 0.9056603773584906,
      "fpr": 0.08928571428571429,
      "fnr": 0.09433962264150944
    },
    "target_sexuality_bisexual": {
      "accuracy": 0.9692982456140351,
      "precision": 0.9347826086956522,
      "recall": 0.9381818181818182,
      "f1": 0.9364791288566243,
      "fpr": 0.020809248554913295,
      "fnr": 0.06181818181818182
    },
    "target_sexuality_gay": {
      "accuracy": 0.9649191959006701,
      "precision": 0.9587719298245614,
      "recall": 0.9629955947136564,
      "f1": 0.9608791208791209,
      "fpr": 0.033523537803138374,
      "fnr": 0.03700440528634361
    },
    "target_sexuality_lesbian": {
      "accuracy": 0.9675213675213675,
      "precision": 0.9498327759197325,
      "recall": 0.9250814332247557,
      "f1": 0.9372937293729373,
      "fpr": 0.01738122827346466,
      "fnr": 0.0749185667752443
    },
    "target_sexuality_straight": {
      "accuracy": 0.9359886201991465,
      "precision": 0.8942731277533039,
      "recall": 0.90625,
      "f1": 0.9002217294900222,
      "fpr": 0.05010438413361169,
      "fnr": 0.09375
    },
    "target_sexuality_other": {
      "accuracy": 0.9681647940074907,
      "precision": 0.9066666666666666,
      "recall": 0.8717948717948718,
      "f1": 0.8888888888888888,
      "fpr": 0.015350877192982455,
      "fnr": 0.1282051282051282
    },
    "target_age_children": {
      "accuracy": 0.9489795918367347,
      "precision": 0.9117647058823529,
      "recall": 0.9393939393939394,
      "f1": 0.9253731343283582,
      "fpr": 0.046153846153846156,
      "fnr": 0.06060606060606061
    },
    "target_age_teenagers": {
      "accuracy": 0.9439252336448598,
      "precision": 0.8780487804878049,
      "recall": 0.972972972972973,
      "f1": 0.9230769230769231,
      "fpr": 0.07142857142857142,
      "fnr": 0.02702702702702703
    },
    "target_age_young_adults": {
      "accuracy": 0.9455782312925171,
      "precision": 0.9245283018867925,
      "recall": 0.9245283018867925,
      "f1": 0.9245283018867925,
      "fpr": 0.0425531914893617,
      "fnr": 0.07547169811320754
    },
    "target_age_middle_aged": {
      "accuracy": 0.922077922077922,
      "precision": 0.9393939393939394,
      "recall": 0.8857142857142857,
      "f1": 0.9117647058823529,
      "fpr": 0.047619047619047616,
      "fnr": 0.11428571428571428
    },
    "target_age_seniors": {
      "accuracy": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "f1": 1.0,
      "fpr": 0.0,
      "fnr": 0.0
    },
    "target_age_other": {
      "accuracy": 0.9333333333333333,
      "precision": 1.0,
      "recall": 0.8888888888888888,
      "f1": 0.9411764705882353,
      "fpr": 0.0,
      "fnr": 0.1111111111111111
    },
    "target_disability_physical": {
      "accuracy": 0.9673202614379085,
      "precision": 0.9849624060150376,
      "recall": 0.9776119402985075,
      "f1": 0.9812734082397003,
      "fpr": 0.10526315789473684,
      "fnr": 0.022388059701492536
    },
    "target_disability_cognitive": {
      "accuracy": 0.9705882352941176,
      "precision": 0.9956896551724138,
      "recall": 0.9705882352941176,
      "f1": 0.9829787234042553,
      "fpr": 0.029411764705882353,
      "fnr": 0.029411764705882353
    },
    "target_disability_neurological": {
      "accuracy": 0.9444444444444444,
      "precision": 0.9782608695652174,
      "recall": 0.9375,
      "f1": 0.9574468085106383,
      "fpr": 0.041666666666666664,
      "fnr": 0.0625
    },
    "target_disability_visually_impaired": {
      "accuracy": 0.8888888888888888,
      "precision": 0.9285714285714286,
      "recall": 0.9285714285714286,
      "f1": 0.9285714285714286,
      "fpr": 0.25,
      "fnr": 0.07142857142857142
    },
    "target_disability_hearing_impaired": {
      "accuracy": 0.8888888888888888,
      "precision": 0.9230769230769231,
      "recall": 0.9230769230769231,
      "f1": 0.9230769230769231,
      "fpr": 0.2,
      "fnr": 0.07692307692307693
    },
    "target_disability_unspecific": {
      "accuracy": 0.9710144927536232,
      "precision": 0.9811320754716981,
      "recall": 0.9811320754716981,
      "f1": 0.9811320754716981,
      "fpr": 0.0625,
      "fnr": 0.018867924528301886
    },
    "target_disability_other": {
      "accuracy": 0.9310344827586207,
      "precision": 1.0,
      "recall": 0.9090909090909091,
      "f1": 0.9523809523809523,
      "fpr": 0.0,
      "fnr": 0.09090909090909091
    }
  },
  "fairness_metrics": {
    "f1_disparity": 0.029924973065889565,
    "fpr_disparity": 0.04535028373015412,
    "fnr_disparity": 0.03241235636641114
  }
}